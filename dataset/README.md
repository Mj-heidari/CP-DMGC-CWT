# ğŸ“˜ CHB-MIT BIDS Preprocessing Pipeline

This module provides a full preprocessing pipeline for the CHB-MIT EEG dataset (in BIDS format). It performs filtering, ICA artifact removal, downsampling, normalization, annotation expansion, segmentation, oversampling, and saving processed epochs in a compact and reproducible format.

The main script is:
```text
dataset/preprocess.py
```

---

# ğŸš€ Features

âœ” Convert raw CHB-MIT data (EDF + TSV events) into clean, labeled segments  
âœ” Add seizure, preictal, interictal, and buffer annotations  
âœ” ICA artifact removal (optional)  
âœ” Band-pass filtering (FIR/IIR)  
âœ” Downsampling (polyphase, FFT, or MNE resample)  
âœ” Z-score or robust normalization  
âœ” Fixed-length epoch extraction (e.g., 5-second segments)  
âœ” Oversampling of preictal or seizure segments  
âœ” Noise metrics and metadata saved per epoch  
âœ” `uint16` compressed representation (optional)  
âœ” Automatic suffix added to filenames to encode preprocessing settings  
âœ” Per-session and per-subject summary statistics  

---

# ğŸ“‚ Output Structure

For each session, the script saves:
```text
session/
â””â”€â”€ eeg/
    â”œâ”€â”€ processed_segments_<suffix>_float.npz # OR uint16.npz
    â”œâ”€â”€ processing_options<suffix>.txt # Reproducibility log
    â”œâ”€â”€ event_stats.csv # Per-event stats
```
Where `<suffix>` describes preprocessing operations (details below).

---

## ğŸ”¤ Filename Suffix Specification

Each output file includes a suffix summarizing preprocessing settings:

- `i` â€” ICA applied  
- `f` â€” Filtering applied  
- `d` â€” Downsampling applied  
- `n` â€” Normalization applied  
- `{s}s` â€” Segment length in seconds  
- `szx{k}` â€” Seizure oversampling factor  
- `prex{k}` â€” Preictal oversampling factor

**Examples:**

- ICA + filter + downsample + 5s segments + 5Ã— preictal + 5Ã— seizure â†’ `_ifd_5s_szx5_prex5`  
- Only downsampling, 4s segments â†’ `_d_4s`  
- Just 6s segments â†’ `_6s`

Suffixes are generated by the `build_suffix()` helper in the script.

---

## ğŸ§  Metadata Saved Per Segment

Each processed epoch includes a row in `meta_df`, containing:

- `event_id` â€” unique ID of source annotation  
- `label` â€” preictal / interictal / seizure / buffer  
- `start_time_in_event` â€” epoch start (seconds from annotation onset)  
- `epoch_index_within_event` â€” integer index within the annotation block  
- `n_segments_in_event` â€” number of segments belonging to the same annotation  
- `augmented` â€” `0` for baseline segments, `1` for overlap-generated segments (oversampling)  
- `pp_mean`, `pp_max` â€” peak-to-peak amplitude stats (across channels)  
- `sd_mean`, `sd_max` â€” std dev stats (across channels)  
- `onset_sec`, `duration_sec` â€” source annotation times

The full `meta_df` is stored inside the NPZ as a dictionary (`meta_df.to_dict('list')`) to make it easy to reload.

---

## âš™ï¸ Command-Line Interface

Run:
```bash
python dataset/preprocess.py --help
```

Key arguments include:

- `--dataset_dir` â€” path to BIDS dataset root  
- `--apply_filter` â€” apply bandpass filter  
- `--filter_type` â€” FIR or IIR  
- `--l_freq`, `--h_freq` â€” filter cutoffs  
- `--apply_ica` â€” enable ICA artifact removal  
- `--apply_downsampling` â€” downsample to `--sfreq_new`  
- `--downsample_method` â€” `polyphase`, `fft`, or `resample`  
- `--normalize` â€” `zscore`, `robust`, or `none`  
- `--preictal_oversample_factor` â€” oversampling factor for preictal  
- `--seizure_oversample_factor` â€” oversampling factor for seizure  
- `--segment_sec` â€” segment duration (seconds)  
- `--subjects` â€” list of subject numbers to process  
- `--save_uint16` â€” save segments as compressed `uint16` (plus scales)

---

## ğŸ¯ Example Usage

Apply FIR filtering, downsample using FFT, and oversample preictal and seizure by 5Ã—:

```bash
python dataset/preprocess.py \
  --apply_filter \
  --filter_type FIR \
  --apply_downsampling \
  --downsample_method fft \
  --preictal_oversample_factor 5 \
  --seizure_oversample_factor 5 \
  --subjects 1 2 3 4 5 6 7 8 9 10 11 13 14 15 16 17 18 19 20 22 23 24 \
  --build_summary
```

Produces a file like:
processed_segments_ifd_5s_szx5_prex5_float.npz

# EEG Dataset Loader and MIL Utilities

- CHBMITDataset: Loads preprocessed EEG data (.npz) for a subject and provides labels, group IDs, and metadata.
- SubsetWithInfo: Subsets the dataset while maintaining labels, group IDs, and metadata.
- UnderSampledDataLoader: Custom dataloader that balances preictal (or seizure) vs. interictal (or non-seizure) samples each epoch.
- MilDataloader: Creates MIL-style bags from the dataset for weakly-supervised training.

- Cross-validation utilities: 
  - Leave-One-Out (LOO) based on seizure events.
  - Stratified or per-event K-Fold splitting with flexible modes (random_split, split, strata, per_event_strata).

- Metadata for each sample is preserved and returned in dataloaders.

## Usage
```python
from dataset import CHBMITDataset

ds = CHBMITDataset(
    dataset_dir="data/BIDS_CHB-MIT",
    subject_id="01",
    task="prediction",  # or "detection"
    suffix="fd_5s_szx5_prex5",
)
print(f"Total samples: {len(ds)}")
print(f"X shape: {ds.X.shape}")
print(f"y distribution: {np.bincount(ds.y)}") 
# 0=interictal, 1=preictal/seizure 
```
Each sample returns a tuple (x, y, meta):
```python
x, y, meta = ds[0]
print(x.shape)  # EEG features
print(y)        # label (0 or 1)
print(meta)     # metadata dict
```
Metadata fields:

- `event_id`: ID of the seizure or preictal event.
- `global_epoch_id`: the unique chronological ID of the segment
- `epoch_index_within_event`: position within the event.
- `n_segments_in_event`: number of segments in the event the segment belongs to.
- `augmented`: flag the segment if it is an augmented segment.
- `onset_sec` & `duration_sec`: timing information.
- Plus other fields like: `pp_mean`, `pp_max`, `sd_mean`, `sd_max`.

## Create Subset
```python
from torch.utils.data import Subset
from dataset import SubsetWithInfo

subset = SubsetWithInfo(ds, indices=[0, 1, 2, 3])
print(subset.y)        # subset labels
print(subset.group_ids) # subset group IDs
print(subset.metadata)  # subset metadata
```
## Use UnderSampledDataLoader
Balances preictal/seizure and interictal/non-seizure samples each epoch.
```python
from dataset import UnderSampledDataLoader

dataloader = UnderSampledDataLoader(subset, batch_size=16)

for batch_data, batch_labels, batch_metas in dataloader:
    print(batch_data.shape)   # [batch_size, channels, time]
    print(batch_labels)       # labels
    print(batch_metas)        # list of dicts for each instance
```
- Bags differ every epoch due to random undersampling.
- `batch_metas` is a list of dictionaries corresponding to each sample in the batch.

## Use MilDataloader for MIL
Creates random bags of size `bag_size` for MIL training.
```python
from dataset import MilDataloader

mil_loader = MilDataloader(subset, batch_size=4, bag_size=8)

for bag_data, bag_labels, bag_metas in mil_loader:
    print(bag_data.shape)   # [batch_size, bag_size, channels, time]
    print(bag_labels)       # labels for each bag (0 or 1)
    print(bag_metas)        # list of lists: metadata for each instance in bag
```
- Each bag contains bag_size instances.
- bag_metas[i] is a list of metadata dictionaries for the i-th bag.
- Bags are reshuffled every epoch.

## Cross-validation splitters
### K-Fold CV:
```python
from dataset import make_cv_splitter

n_folds = 5
cv_splits, _ = make_cv_splitter(ds, method="KFold", n_fold=n_folds, shuffle=True, mode="strata")

for fold_idx, (train_set, val_set) in enumerate(cv_splits):
    print(f"Fold {fold_idx}:")
    print(f"  Train samples: {len(train_set)}, Validation samples: {len(val_set)}")
```
### Leave-One-Out CV:
```python 
from dataset import make_cv_splitter

loo_splits, _ = make_cv_splitter(ds, method="LOO", shuffle=True)

for train_set, test_set in loo_splits:
    print(f"Train: {len(train_set)}, Test: {len(test_set)}")
```
### CV Notes:
- Supports multiple modes for K-Fold:
  - "random_split": random split per class
  - "split": chronological split
  - "strata": stratified split per class
  - "per_event_strata": stratified within each seizure/interictal event
- Handles interictal and preictal/seizure samples separately.
- Ensures temporal integrity for time-series data.